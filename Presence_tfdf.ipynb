{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!source .venv/bin/activate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import influxdb_client, os, time\n",
    "from influxdb_client import InfluxDBClient, Point, WritePrecision\n",
    "from influxdb_client.client.write_api import SYNCHRONOUS\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature, set_signature\n",
    "import mlflow.keras\n",
    "import yaml\n",
    "from pickle import dump\n",
    "import math\n",
    "import os\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt \n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "with open('Presences_keras_random_forest.yaml', 'r') as file:\n",
    "    variables = yaml.safe_load(file)\n",
    "\n",
    "print(f\"{variables}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = influxdb_client.InfluxDBClient(\n",
    "    url=variables[\"influx_db\"][\"url\"],\n",
    "    token=variables[\"influx_db\"][\"token\"],\n",
    "    org=variables[\"influx_db\"][\"org\"],\n",
    "    verify_ssl=False,\n",
    "    timeout=180000)\n",
    "\n",
    "query_api = client.query_api()\n",
    "\n",
    "# |> range(start: 2024-02-20T17:00:00Z)\n",
    "start_time = \"2024-02-20T17:00:00Z\"\n",
    "query_start = datetime.strptime(start_time, \"%Y-%m-%dT%H:%M:%SZ\") - timedelta(days=5) \n",
    "\n",
    "base_query = \"\"\"\n",
    "        from(bucket: \"homeassistant\")\n",
    "            |> range(start: )\n",
    "            |> filter(fn: (r) => r[\"entity_id\"] == \"entity_name\")\n",
    "            |> filter(fn: (r) => r[\"_field\"] == \"value\")\n",
    "            |> fill(usePrevious: true)\n",
    "            |> drop(columns: [\"result\", \"table\", \"_start\", \"_stop\", \"_field\", \"source\",\"domain\",\"_measurement\", \"friendly_name\"])\n",
    "            |> pivot(rowKey: [\"_time\"], columnKey: [\"entity_id\"], valueColumn: \"_value\")\n",
    "            |> yield(name: \"last\")\"\"\"\n",
    "base_query = base_query.replace(\"start: \", f'start: {datetime.strftime(query_start, \"%Y-%m-%dT%H:%M:%SZ\")}')\n",
    "for nb, entity in enumerate(variables[\"data\"]):\n",
    "    print(entity)\n",
    "    entity = entity.split(\":\")\n",
    "    query = base_query.replace(\"entity_name\", entity[0], 1)\n",
    "    if len(entity)> 1 and {entity[1]} != \"\":\n",
    "        query = query.replace('r[\"_field\"] == \"value\"', f'r[\"_field\"] == \"{entity[1]}\"')\n",
    "        query = query.replace('columnKey: [\"entity_id\"]', f'columnKey: [\"_field\"]')\n",
    "        query = query.replace(\n",
    "            'drop(columns: [\"result\", \"table\", \"_start\", \"_stop\", \"_field\", \"source\",\"domain\",\"_measurement\", \"friendly_name\"])',\n",
    "            'drop(columns: [\"result\", \"table\", \"_start\", \"_stop\", \"entity_id\", \"source\",\"domain\",\"_measurement\", \"friendly_name\"])'\n",
    "        )\n",
    "    if len(entity)> 2 and {entity[2]} != \"\":\n",
    "       query = query.replace('fn: last,', f'fn: {entity[2]},')\n",
    "    # print(query)\n",
    "    df = query_api.query_data_frame(query, org=variables[\"influx_db\"][\"org\"])\n",
    "    print(df.head())\n",
    "    try:\n",
    "        df.set_index('_time', inplace=True)\n",
    "        df.drop([\"result\", \"table\"], axis=1, inplace=True)\n",
    "        if nb == 0:\n",
    "            full_df = df.copy()\n",
    "        else:\n",
    "            full_df = full_df.join(df,on=\"_time\", how='outer')\n",
    "    except KeyError:\n",
    "        print(f\"{entity[1]} was not found\")\n",
    "        if len(entity)> 2:\n",
    "            full_df[entity[1]] =  entity[2]\n",
    "        else: \n",
    "            full_df[entity[1]] = np.nan\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(full_df.shape)\n",
    "print(full_df.head())\n",
    "feature_names = variables[\"features\"]\n",
    "\n",
    "for feature in variables[\"numeric_features\"]:\n",
    "    full_df[feature] = pd.Series.interpolate(full_df[feature])\n",
    "\n",
    "full_df.ffill(inplace=True)\n",
    "full_df[\"home_status\"] = full_df[\"in_bed\"] + full_df[\"presence\"]\n",
    "full_df = full_df[full_df['ha_started']==1]\n",
    "full_df.reset_index(inplace=True)\n",
    "full_df = full_df[full_df['_time']> start_time]\n",
    "new_df = full_df[variables[\"features\"] + variables[\"targets\"]].copy()\n",
    "print(new_df.head())\n",
    "new_df.dropna(inplace=True)\n",
    "new_df.reset_index(inplace=True)\n",
    "new_df.drop_duplicates(feature_names, inplace=True, ignore_index=True)\n",
    "print(new_df.dtypes)\n",
    "\n",
    "\n",
    "print(new_df.shape)\n",
    "\n",
    "target = new_df[variables[\"targets\"]]\n",
    "numeric_features = new_df[feature_names]\n",
    "numeric_features.head(20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mlflow setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"MLFLOW_TRACKING_INSECURE_TLS\"] = \"true\"\n",
    "os.environ[\"MLFLOW_TRACKING_URI\"]=\"http://192.168.0.2:5051\"\n",
    "mlflow.set_tracking_uri(uri=\"http://192.168.0.2:5051\")\n",
    "mlflow.set_tracking_uri(uri=variables[\"mlflow\"][\"url\"])\n",
    "mlflow.set_experiment(\"Presence detection Keras.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    numeric_features, target, test_size=0.2, random_state=42\n",
    ")\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model, pipeline setup and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum number of decision trees. The effective number of trained trees can be smaller if early stopping is enabled.\n",
    "NUM_TREES = 250\n",
    "# Minimum number of examples in a node.\n",
    "MIN_EXAMPLES = 6\n",
    "# Maximum depth of the tree. max_depth=1 means that all trees will be roots.\n",
    "MAX_DEPTH = 5\n",
    "# Ratio of the dataset (sampling without replacement) used to train individual trees for the random sampling method.\n",
    "SUBSAMPLE = 0.65\n",
    "# Control the sampling of the datasets used to train individual trees.\n",
    "SAMPLING_METHOD = \"RANDOM\"\n",
    "# Ratio of the training dataset used to monitor the training. Require to be >0 if early stopping is enabled.\n",
    "VALIDATION_RATIO = 0.2\n",
    "\n",
    "cpu_count = os.cpu_count()\n",
    "n_jobs = int(math.floor((cpu_count)))\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "\n",
    "    mlflow.autolog()\n",
    "    import tensorflow_decision_forests as tfdf\n",
    "    from sklearn.metrics import accuracy_score, log_loss, precision_score,recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "    from sklearn.metrics import make_scorer, classification_report\n",
    "    \n",
    "    # Create a Random Search tuner with 50 trials and automatic hp configuration.\n",
    "    tuner = tfdf.tuner.RandomSearch(num_trials=50, use_predefined_hps=True, trial_num_threads=16)\n",
    "    \n",
    "    model = tfdf.keras.GradientBoostedTreesModel(\n",
    "        tuner=tuner,\n",
    "        validation_ratio=VALIDATION_RATIO,\n",
    "        task=tfdf.keras.Task.CLASSIFICATION,\n",
    "        verbose=2,\n",
    "        num_threads=n_jobs,\n",
    "    )\n",
    "\n",
    "    model.compile(metrics=[\"accuracy\", precision_score])\n",
    "\n",
    "    os.environ[\"MLFLOW_TRACKING_INSECURE_TLS\"] = \"true\"\n",
    "    mlflow.set_tracking_uri(uri=variables[\"mlflow\"][\"url\"])\n",
    "    mlflow.set_experiment(\"Presence detection Keras.\")\n",
    "    # define the search\n",
    "    history = model.fit(\n",
    "        X_train.values,\n",
    "        y_train.values,\n",
    "        # callbacks=[mlflow.keras.MLflowCallback()],\n",
    "    )\n",
    "    # accuracy, f1_score, _ = model.evaluate(X_test.values, y_test.values)\n",
    "    \n",
    "\n",
    "    # print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "    # mlflow.log_metric(\"Test accuracy\", accuracy)\n",
    "\n",
    "    #model = model.export_model()\n",
    "    # summarize the loaded model\n",
    "    model.summary()\n",
    "    signature = infer_signature(numeric_features, model.predict(numeric_features))\n",
    "    mlflow.tensorflow.log_model(\n",
    "        model, 'model',\n",
    "        # signature=signature,\n",
    "        extra_pip_requirements=[\"tensorflow-decision-forests\"]\n",
    "    )\n",
    "    pred = model.predict(X_test)\n",
    "    pred = np.argmax (pred, axis = 1)\n",
    "    class_report = classification_report(y_test, pred, output_dict=True)\n",
    "    print(class_report)\n",
    "    \n",
    "    ConfusionMatrixDisplay.from_predictions(\n",
    "        pred,\n",
    "        y_test.values,\n",
    "        cmap=plt.cm.Blues,\n",
    "        normalize='true',\n",
    "    )\n",
    "    plt.savefig(\"test_confusion_matrix.png\")\n",
    "    \n",
    "    inspector = model.make_inspector()\n",
    "    print(inspector.evaluation())\n",
    "    print(inspector.variable_importances())\n",
    "    mlflow.log_metrics(inspector.evaluation().to_dict())\n",
    "    class_report.pop(\"accuracy\")\n",
    "    for class_or_avg, metrics_dict in class_report.items():\n",
    "        for metric, value in metrics_dict.items():\n",
    "            mlflow.log_metric(class_or_avg + '_' + metric,value)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_dict =  mlflow.last_active_run().to_dictionary() \n",
    "print(run_dict)\n",
    "shutil.copy(\"test_confusion_matrix.png\", f\"/mnt/nfs/mlflow/{run_dict['info']['experiment_id']}/{run_dict['info']['run_id']}/artifacts/\")\n",
    "signature = infer_signature(numeric_features, model.predict(numeric_features))\n",
    "set_signature(f\"runs:/{run_dict['info']['run_id']}/model\", signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the tuning logs.\n",
    "tuning_logs = model.make_inspector().tuning_logs()\n",
    "print(tuning_logs.head())\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(tuning_logs[\"score\"], label=\"current trial\")\n",
    "plt.plot(tuning_logs[\"score\"].cummin(), label=\"best trial\")\n",
    "plt.xlabel(\"Tuning step\")\n",
    "plt.ylabel(\"Tuning score\")\n",
    "plt.legend()\n",
    "plt.savefig(\"tuning_steps.png\")\n",
    "shutil.copy(\"tuning_steps.png\", f\"/mnt/nfs/mlflow/{run_dict['info']['experiment_id']}/{run_dict['info']['run_id']}/artifacts/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(\n",
    "        pred,\n",
    "        y_test.values,\n",
    "        cmap=plt.cm.Blues,\n",
    "    #    normalize='true',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If model log fails run this:\n",
    "# import tensorflow\n",
    "# tensorflow.saved_model.save(\n",
    "#     model,\n",
    "#     f\"/mnt/nfs/mlflow/{run_dict['info']['experiment_id']}/{run_dict['info']['run_id']}/artifacts/tfdf_model\",\n",
    "# )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
